{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key', 0.013486821959253156),\n",
       " ('clipper', 0.012178081084789322),\n",
       " ('chip', 0.01153715350350748),\n",
       " ('encryption', 0.011465426118856408),\n",
       " ('keys', 0.009241430217923606),\n",
       " ('government', 0.00824393197474505),\n",
       " ('escrow', 0.00792521350323413),\n",
       " ('nsa', 0.00705403412690026),\n",
       " ('be', 0.006526355370081302),\n",
       " ('algorithm', 0.006478630880538405)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_game_team_games_he</td>\n",
       "      <td>[game, team, games, he, players, season, hocke...</td>\n",
       "      <td>[\\nNo.  Patrick Roy is the reason the game was...</td>\n",
       "      <td>game - team - games - he - players - season - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_to_the_of_and</td>\n",
       "      <td>[to, the, of, and, is, for, in, you, it, that]</td>\n",
       "      <td>[----- Begin Included Message -----\\n\\nThe fol...</td>\n",
       "      <td>to - the - of - and - is - for - in - you - it...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>16</td>\n",
       "      <td>16_armenian_turkish_armenians_genocide</td>\n",
       "      <td>[armenian, turkish, armenians, genocide, turke...</td>\n",
       "      <td>[\\n\\nPoor 'Poly'. I see you're preparing the g...</td>\n",
       "      <td>armenian - turkish - armenians - genocide - tu...</td>\n",
       "      <td>0.448945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4_drive_scsi_drives_ide</td>\n",
       "      <td>[drive, scsi, drives, ide, disk, controller, h...</td>\n",
       "      <td>[\\n\\n\\n\\n\\n\\nI have been using both IDE (or MF...</td>\n",
       "      <td>drive - scsi - drives - ide - disk - controlle...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>95</td>\n",
       "      <td>95_tape_backup_tapes_drive</td>\n",
       "      <td>[tape, backup, tapes, drive, device, munroe, w...</td>\n",
       "      <td>[I have a Colorado Memory Systems Jumbo 250 ta...</td>\n",
       "      <td>tape - backup - tapes - drive - device - munro...</td>\n",
       "      <td>0.737134</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "      <td>35</td>\n",
       "      <td>35_doctor_patients_quack_gordon</td>\n",
       "      <td>[doctor, patients, quack, gordon, disease, can...</td>\n",
       "      <td>[: Am I justified in being pissed off at this ...</td>\n",
       "      <td>doctor - patients - quack - gordon - disease -...</td>\n",
       "      <td>0.864373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "      <td>187</td>\n",
       "      <td>187_ground_grounding_conductor_neutral</td>\n",
       "      <td>[ground, grounding, conductor, neutral, wire, ...</td>\n",
       "      <td>[\\nNot according to the NEC nor the CEC, as ex...</td>\n",
       "      <td>ground - grounding - conductor - neutral - wir...</td>\n",
       "      <td>0.369616</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>88</td>\n",
       "      <td>88_fan_cpu_heat_sink</td>\n",
       "      <td>[fan, cpu, heat, sink, fans, cooling, chip, ho...</td>\n",
       "      <td>[N(P&gt;Just got a 66MHz 486DX2 system, and am co...</td>\n",
       "      <td>fan - cpu - heat - sink - fans - cooling - chi...</td>\n",
       "      <td>0.985038</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "      <td>17</td>\n",
       "      <td>17_den_polygon_points_algorithm</td>\n",
       "      <td>[den, polygon, points, algorithm, xxxx, plane,...</td>\n",
       "      <td>[\\nSorry!! :-)\\n\\nCall the four points A, B, C...</td>\n",
       "      <td>den - polygon - points - algorithm - xxxx - pl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "      <td>5</td>\n",
       "      <td>5_car_cars_engine_ford</td>\n",
       "      <td>[car, cars, engine, ford, toyota, miles, musta...</td>\n",
       "      <td>[\\n\\n\\n\\nYou know, I'm a Ford fan, I must say,...</td>\n",
       "      <td>car - cars - engine - ford - toyota - miles - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Document  Topic  \\\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...      0   \n",
       "1      My brother is in the market for a high-perform...     -1   \n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...     16   \n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...      4   \n",
       "4      1)    I have an old Jasmine drive which I cann...     95   \n",
       "...                                                  ...    ...   \n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...     35   \n",
       "18842  \\nNot in isolated ground recepticles (usually ...    187   \n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...     88   \n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...     17   \n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....      5   \n",
       "\n",
       "                                         Name  \\\n",
       "0                        0_game_team_games_he   \n",
       "1                            -1_to_the_of_and   \n",
       "2      16_armenian_turkish_armenians_genocide   \n",
       "3                     4_drive_scsi_drives_ide   \n",
       "4                  95_tape_backup_tapes_drive   \n",
       "...                                       ...   \n",
       "18841         35_doctor_patients_quack_gordon   \n",
       "18842  187_ground_grounding_conductor_neutral   \n",
       "18843                    88_fan_cpu_heat_sink   \n",
       "18844         17_den_polygon_points_algorithm   \n",
       "18845                  5_car_cars_engine_ford   \n",
       "\n",
       "                                          Representation  \\\n",
       "0      [game, team, games, he, players, season, hocke...   \n",
       "1         [to, the, of, and, is, for, in, you, it, that]   \n",
       "2      [armenian, turkish, armenians, genocide, turke...   \n",
       "3      [drive, scsi, drives, ide, disk, controller, h...   \n",
       "4      [tape, backup, tapes, drive, device, munroe, w...   \n",
       "...                                                  ...   \n",
       "18841  [doctor, patients, quack, gordon, disease, can...   \n",
       "18842  [ground, grounding, conductor, neutral, wire, ...   \n",
       "18843  [fan, cpu, heat, sink, fans, cooling, chip, ho...   \n",
       "18844  [den, polygon, points, algorithm, xxxx, plane,...   \n",
       "18845  [car, cars, engine, ford, toyota, miles, musta...   \n",
       "\n",
       "                                     Representative_Docs  \\\n",
       "0      [\\nNo.  Patrick Roy is the reason the game was...   \n",
       "1      [----- Begin Included Message -----\\n\\nThe fol...   \n",
       "2      [\\n\\nPoor 'Poly'. I see you're preparing the g...   \n",
       "3      [\\n\\n\\n\\n\\n\\nI have been using both IDE (or MF...   \n",
       "4      [I have a Colorado Memory Systems Jumbo 250 ta...   \n",
       "...                                                  ...   \n",
       "18841  [: Am I justified in being pissed off at this ...   \n",
       "18842  [\\nNot according to the NEC nor the CEC, as ex...   \n",
       "18843  [N(P>Just got a 66MHz 486DX2 system, and am co...   \n",
       "18844  [\\nSorry!! :-)\\n\\nCall the four points A, B, C...   \n",
       "18845  [\\n\\n\\n\\nYou know, I'm a Ford fan, I must say,...   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "0      game - team - games - he - players - season - ...     1.000000   \n",
       "1      to - the - of - and - is - for - in - you - it...     0.000000   \n",
       "2      armenian - turkish - armenians - genocide - tu...     0.448945   \n",
       "3      drive - scsi - drives - ide - disk - controlle...     1.000000   \n",
       "4      tape - backup - tapes - drive - device - munro...     0.737134   \n",
       "...                                                  ...          ...   \n",
       "18841  doctor - patients - quack - gordon - disease -...     0.864373   \n",
       "18842  ground - grounding - conductor - neutral - wir...     0.369616   \n",
       "18843  fan - cpu - heat - sink - fans - cooling - chi...     0.985038   \n",
       "18844  den - polygon - points - algorithm - xxxx - pl...     1.000000   \n",
       "18845  car - cars - engine - ford - toyota - miles - ...     1.000000   \n",
       "\n",
       "       Representative_document  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "18841                    False  \n",
       "18842                    False  \n",
       "18843                    False  \n",
       "18844                    False  \n",
       "18845                    False  \n",
       "\n",
       "[18846 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Fine-tune your topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "topic_model = BERTopic(representation_model=representation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTopic(calculate_probabilities=False, ctfidf_model=ClassTfidfTransformer(...), embedding_model=None, hdbscan_model=HDBSCAN(...), language=english, low_memory=False, min_topic_size=10, n_gram_range=(1, 1), nr_topics=None, representation_model=OpenAI(...), seed_topic_list=None, top_n_words=10, umap_model=UMAP(...), vectorizer_model=CountVectorizer(...), verbose=False, zeroshot_min_similarity=0.7, zeroshot_topic_list=None)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "\n",
    "\n",
    "# Fine-tune topic representations with GPT\n",
    "client = openai.OpenAI(api_key=OPENAI_KEY)\n",
    "representation_model = OpenAI(client, model=\"gpt-3.5-turbo\", chat=True)\n",
    "topic_model = BERTopic(representation_model=representation_model)\n",
    "print(topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Integrating ChatGPT into your application depends on the environment and programming language you\\'re using. Generally, this involves using the OpenAI API. Below are the steps for a typical integration using Python, which is a common language for such tasks:\\n\\n### 1. Sign Up for OpenAI API\\n\\nFirst, you need to sign up on the OpenAI website and obtain an API key that you will use to authenticate your requests.\\n\\n### 2. Install Required Libraries\\n\\nEnsure you have `requests` installed in your Python environment to make HTTP requests. If you\\'re using pip, you can install it using:\\n\\n```bash\\npip install requests\\n```\\n\\n### 3. Write the Code\\n\\nHere’s a simple example of how to use the OpenAI API in Python:\\n\\n```python\\nimport requests\\n\\nAPI_KEY = \\'your_api_key_here\\'\\nAPI_URL = \\'https://api.openai.com/v1/chat/completions\\'\\n\\nheaders = {\\n    \\'Authorization\\': f\\'Bearer {API_KEY}\\',\\n    \\'Content-Type\\': \\'application/json\\',\\n}\\n\\ndef chat_with_gpt(prompt):\\n    data = {\\n        \"model\": \"gpt-3.5-turbo\",  # Use the appropriate model\\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\\n        \"max_tokens\": 100,  # You can adjust the max tokens\\n        \"temperature\": 0.7,  # Adjust creativity \\n    }\\n\\n    response = requests.post(API_URL, headers=headers, json=data)\\n    if response.status_code == 200:\\n        return response.json()[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n    else:\\n        print(f\"Error {response.status_code}: {response.text}\")\\n        return None\\n\\n# Example usage\\nuser_input = \"Tell me a joke.\"\\nresponse = chat_with_gpt(user_input)\\nprint(\"ChatGPT:\", response)\\n```\\n\\n### 4. Replace API Key\\n\\nDon\\'t forget to replace `\\'your_api_key_here\\'` with your actual OpenAI API key.\\n\\n### 5. Run Your Code\\n\\nRun your script, and it should communicate with the ChatGPT model to get responses based on your prompts.\\n\\n### 6. Handle Different Use Cases\\n\\nYou can integrate this function into a larger application, such as a web app using Flask or Django, or into a chatbot framework. Depending on your use case, you will need to adjust how input is received and how output is displayed.\\n\\n### Notes\\n\\n- **Rate Limits**: Be aware of the rate limits of your API usage as specified in your OpenAI account.\\n- **Error Handling**: In production code, ensure to implement robust error handling and logging.\\n- **Environment Variables**: For security purposes, it\\'s better to store your API key in environment variables rather than hardcoding it.\\n\\n### Other Languages and Frameworks\\n\\nIf you\\'re working in another programming language (like JavaScript, Ruby, etc.), the concept remains similar—you\\'ll make API requests to the OpenAI endpoint and handle the response according to the syntax and conventions of that language.\\n\\nLet me know if you need help with a specific programming language or environment!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=OPENAI_KEY,\n",
    ")\n",
    "\n",
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "chat_gpt(\"how to put Chat GPT into the code I have\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
